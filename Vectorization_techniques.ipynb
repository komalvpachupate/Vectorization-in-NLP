{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bag of Words"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It involves three operations:\n",
    "    \n",
    "1) Tokenization:\n",
    "    First, the input text is tokenized. A sentence is represented as a list of its constituent words, and it’s done \n",
    "    for all the input sentences.\n",
    "    \n",
    "2) Vocabulary creation:\n",
    "    Of all the obtained tokenized words, only unique words are selected to create the vocabulary and then sorted by  \n",
    "    alphabetical order.\n",
    "    \n",
    "3) Vector creation\n",
    "    Finally, a sparse matrix is created for the input, out of the frequency of vocabulary words. In this sparse matrix, \n",
    "    each row is a sentence vector whose length (the columns of the matrix) is equal to the size of the vocabulary.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "sents = ['coronavirus is a highly infectious disease',\n",
    "   'coronavirus affects older people the most',\n",
    "   'older people are at high risk due to this disease']\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X = cv.fit_transform(sents)\n",
    "X = X.toarray()\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affects',\n",
       " 'are',\n",
       " 'at',\n",
       " 'coronavirus',\n",
       " 'disease',\n",
       " 'due',\n",
       " 'high',\n",
       " 'highly',\n",
       " 'infectious',\n",
       " 'is',\n",
       " 'most',\n",
       " 'older',\n",
       " 'people',\n",
       " 'risk',\n",
       " 'the',\n",
       " 'this',\n",
       " 'to']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cv.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affects older',\n",
       " 'are at',\n",
       " 'at high',\n",
       " 'coronavirus affects',\n",
       " 'coronavirus is',\n",
       " 'due to',\n",
       " 'high risk',\n",
       " 'highly infectious',\n",
       " 'infectious disease',\n",
       " 'is highly',\n",
       " 'older people',\n",
       " 'people are',\n",
       " 'people the',\n",
       " 'risk due',\n",
       " 'the most',\n",
       " 'this disease',\n",
       " 'to this']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1 = CountVectorizer(ngram_range=(2,2))  #we can also combine unigrams, bigrams, trigrams, and more, to form feature space.\n",
    "X = cv1.fit_transform(sents)\n",
    "X = X.toarray()\n",
    "sorted(cv1.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TF-IDF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TF-IDF or Term Frequency–Inverse Document Frequency, is a numerical statistic that’s intended to reflect how important a word is to a document. Although it’s another frequency-based method, it’s not as naive as Bag of Words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
